{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from googleapiclient.discovery import build\n",
    "import json\n",
    "import csv\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call successful. Response data:\n",
      "[{'kind': 'youtube#searchResult', 'etag': 'KNhgDQrc7f_us7bPJ6sfgZpDuWM', 'id': {'kind': 'youtube#video', 'videoId': 'u6NE5up9ZGQ'}, 'snippet': {'publishedAt': '2023-07-31T19:49:44Z', 'channelId': 'UCV5HXUHFR-yuSb7qDJ5_80g', 'title': '2023 Ashes 5th Test, Day 5 Highlights | Wide World of Sports', 'description': 'Watch all the highlights from Day 5 of The Fifth Test, live from The Oval, London. FULL REPLAYS AND MINIS: ...', 'thumbnails': {'default': {'url': 'https://i.ytimg.com/vi/u6NE5up9ZGQ/default.jpg', 'width': 120, 'height': 90}, 'medium': {'url': 'https://i.ytimg.com/vi/u6NE5up9ZGQ/mqdefault.jpg', 'width': 320, 'height': 180}, 'high': {'url': 'https://i.ytimg.com/vi/u6NE5up9ZGQ/hqdefault.jpg', 'width': 480, 'height': 360}}, 'channelTitle': 'Wide World of Sports', 'liveBroadcastContent': 'none', 'publishTime': '2023-07-31T19:49:44Z'}}]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Replace 'YOUR_API_KEY' with your actual YouTube Data API key\n",
    "API_KEY = 'AIzaSyDhyph3y_r3HKFoGYRJgutCPMqGA7-ciPA'\n",
    "\n",
    "def test_youtube_data_api(api_key):\n",
    "    base_url = 'https://www.googleapis.com/youtube/v3/search'\n",
    "    params = {\n",
    "        'part': 'snippet',\n",
    "        'maxResults': 1,  # Fetch only one result for testing\n",
    "        'q': 'test',  # Your search query, you can use any keyword here\n",
    "        'key': api_key\n",
    "    }\n",
    "    response = requests.get(base_url, params=params)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        if 'items' in data:\n",
    "            print(\"API call successful. Response data:\")\n",
    "            print(data['items'])\n",
    "        else:\n",
    "            print(\"API call successful, but no items found in response.\")\n",
    "    else:\n",
    "        print(f\"An HTTP error occurred: {response.status_code}\")\n",
    "        print(response.text)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    test_youtube_data_api(API_KEY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            Video Name  \\\n",
      "0            Step Up: High Water, Episode 1 - CENSORED   \n",
      "1    CHHAKKA PANJA (Full Movie) - Superhit Nepali F...   \n",
      "2    High Quality Advice #explore #viral #motivatio...   \n",
      "3    DREAMS (Full Movie) Anmol KC | Samragyee RL Sh...   \n",
      "4    10 MIN FULL BODY FAT BURN WORKOUT | WEIGHT LOS...   \n",
      "..                                                 ...   \n",
      "195                                   One Winter Night   \n",
      "196                                       Too Far Gone   \n",
      "197                                              Alone   \n",
      "198                      Community - Social Psychology   \n",
      "199                                           Aperitif   \n",
      "\n",
      "                   Channel ID     Views   Likes  Dislikes  Comments  \\\n",
      "0    UCkM3cLfmWBSFoEU-xVnQ-dw         0       0         0      5868   \n",
      "1    UCrzyJYtjLOTfnUur8hsr7ow  22639192  120531         0      7473   \n",
      "2    UCTvVYLCS613HBHJthDfT7dA  22840507       0         0     21461   \n",
      "3    UCrzyJYtjLOTfnUur8hsr7ow  16143889  125883         0      6735   \n",
      "4    UCa_JUG9hl8D7S6jH7nWTURA  12339029  184727         0      1371   \n",
      "..                        ...       ...     ...       ...       ...   \n",
      "195  UCuVPpxrm2VAgpH3Ktln4HXg         0      11         0         2   \n",
      "196  UClzuZIu2IAW5ipWVhAdTKtg         0      25         0         1   \n",
      "197  UClzuZIu2IAW5ipWVhAdTKtg         0      16         0         0   \n",
      "198  UCL9ry2ykYEVWz50lnkuNgKw         0      10         0         0   \n",
      "199  UCRudrvv95E7gSfhNf1xruvw         0      22         0         5   \n",
      "\n",
      "        Time of Uploading  \n",
      "0    2018-01-31T16:59:37Z  \n",
      "1    2017-01-13T01:37:07Z  \n",
      "2    2023-05-21T19:19:53Z  \n",
      "3    2016-09-09T16:55:30Z  \n",
      "4    2019-10-05T14:44:39Z  \n",
      "..                    ...  \n",
      "195  2023-06-20T14:00:02Z  \n",
      "196  2014-03-03T00:12:39Z  \n",
      "197  2014-03-10T17:15:37Z  \n",
      "198  2014-03-04T19:08:11Z  \n",
      "199  2014-03-01T11:05:50Z  \n",
      "\n",
      "[200 rows x 7 columns]\n",
      "Data has been exported to youtube_videos.csv.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Replace 'YOUR_API_KEY' with your actual YouTube Data API key\n",
    "API_KEY = 'AIzaSyDhyph3y_r3HKFoGYRJgutCPMqGA7-ciPA'\n",
    "\n",
    "\n",
    "def get_random_videos(api_key, max_results=200, min_views=10000):\n",
    "    base_url = 'https://www.googleapis.com/youtube/v3/search'\n",
    "    params = {\n",
    "        'part': 'snippet',\n",
    "        'maxResults': max_results,\n",
    "        'type': 'video',  # Fetch only videos\n",
    "        'order': 'viewCount',  # Sort by view count\n",
    "        'q': '',  # Fetch all videos (empty query)\n",
    "        'key': api_key\n",
    "    }\n",
    "\n",
    "    videos = []\n",
    "    while len(videos) < max_results:\n",
    "        response = requests.get(base_url, params=params)\n",
    "\n",
    "        if response.status_code != 200:\n",
    "            print(f\"An HTTP error occurred: {response.status_code}\")\n",
    "            print(response.text)\n",
    "            break\n",
    "\n",
    "        data = response.json()\n",
    "        if 'items' in data:\n",
    "            videos.extend(data['items'])\n",
    "            if not data.get('nextPageToken'):\n",
    "                break\n",
    "            params['pageToken'] = data['nextPageToken']\n",
    "        else:\n",
    "            print(\"No videos found in response.\")\n",
    "            break\n",
    "\n",
    "    return videos\n",
    "\n",
    "def get_video_statistics(api_key, video_id):\n",
    "    base_url = 'https://www.googleapis.com/youtube/v3/videos'\n",
    "    params = {\n",
    "        'part': 'statistics',\n",
    "        'id': video_id,\n",
    "        'key': api_key\n",
    "    }\n",
    "\n",
    "    response = requests.get(base_url, params=params)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        if 'items' in data and data['items']:\n",
    "            return data['items'][0]['statistics']\n",
    "    else:\n",
    "        print(f\"An HTTP error occurred while fetching statistics for Video ID: {video_id}.\")\n",
    "        print(f\"Status Code: {response.status_code}\")\n",
    "        print(response.text)\n",
    "    return {}\n",
    "\n",
    "def extract_video_data(video_item):\n",
    "    snippet = video_item['snippet']\n",
    "    video_id = video_item['id']['videoId']\n",
    "    channel_id = snippet['channelId']\n",
    "    video_title = snippet['title']\n",
    "    published_at = snippet['publishedAt']\n",
    "\n",
    "    # Fetch detailed statistics for the video\n",
    "    video_statistics = get_video_statistics(API_KEY, video_id)\n",
    "\n",
    "    view_count = int(video_statistics.get('viewCount', 0))\n",
    "    like_count = int(video_statistics.get('likeCount', 0))\n",
    "    dislike_count = int(video_statistics.get('dislikeCount', 0))\n",
    "    comment_count = int(video_statistics.get('commentCount', 0))\n",
    "\n",
    "    return {\n",
    "        'Video Name': video_title,\n",
    "        'Channel ID': channel_id,\n",
    "        'Views': view_count,\n",
    "        'Likes': like_count,\n",
    "        'Dislikes': dislike_count,\n",
    "        'Comments': comment_count,\n",
    "        'Time of Uploading': published_at\n",
    "    }\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Fetch 200 random videos with over 10,000 views\n",
    "    videos = get_random_videos(API_KEY, max_results=200, min_views=10000)\n",
    "\n",
    "    # Extract data for each video and create a DataFrame\n",
    "    video_data = [extract_video_data(video) for video in videos]\n",
    "    df = pd.DataFrame(video_data)\n",
    "\n",
    "    # Export the DataFrame to a CSV file\n",
    "    csv_file = 'youtube_videos.csv'\n",
    "    df.to_csv(csv_file, index=False, quoting=csv.QUOTE_NONNUMERIC)\n",
    "\n",
    "    print(df)\n",
    "    print(f\"Data has been exported to {csv_file}.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
